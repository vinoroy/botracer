{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 20, 224, 3)\n",
      "(550,)\n"
     ]
    }
   ],
   "source": [
    "X = np.load('trackTrainImages.npy')\n",
    "y = np.load('trackPos.npy')\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = X\n",
    "y_train = y\n",
    "\n",
    "\n",
    "X_test = X\n",
    "y_test = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from integers to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize to range 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training data into a training set and a validation set\n",
    "X_train, X_valid = X_train[:-100], X_train[-100:]\n",
    "y_train, y_valid = y_train[:-100], y_train[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# create the MLP model\n",
    "inputs = Input(shape=(20,224,3))\n",
    "\n",
    "conv2D_1 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(inputs)\n",
    "maxPool_1 = MaxPooling2D(pool_size=2,strides=2)(conv2D_1)\n",
    "batch_1 = BatchNormalization()(maxPool_1)\n",
    "\n",
    "\n",
    "conv2D_2 = Conv2D(filters=15,kernel_size=2,strides=1,activation='relu')(batch_1)\n",
    "maxPool_2 = MaxPooling2D(pool_size=2,strides=1)(conv2D_2)\n",
    "batch_2 = BatchNormalization()(maxPool_2)\n",
    "\n",
    "conv2D_3 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(batch_2)\n",
    "maxPool_3 = MaxPooling2D(pool_size=2,strides=1)(conv2D_3)\n",
    "batch_3 = BatchNormalization()(maxPool_3)\n",
    "\n",
    "conv2D_4 = Conv2D(filters=15,kernel_size=3,strides=1,activation='relu')(batch_3)\n",
    "maxPool_4 = MaxPooling2D(pool_size=2,strides=1)(conv2D_4)\n",
    "batch_4 = BatchNormalization()(maxPool_4)\n",
    "\n",
    "\n",
    "flat = Flatten()(batch_4)\n",
    "dense_1 = Dense(units=64,activation='relu')(flat)\n",
    "outputs = Dense(units=1,activation='linear')(dense_1)\n",
    "\n",
    "model = keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 20, 224, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 18, 222, 15)       420       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 9, 111, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 9, 111, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 110, 15)        915       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 109, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 109, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 107, 15)        2040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 106, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 106, 15)        60        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 2, 104, 15)        2040      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 103, 15)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 103, 15)        60        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1545)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                98944     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 104,664\n",
      "Trainable params: 104,544\n",
      "Non-trainable params: 120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comile the model unsing categorical_crossentropy loss function\n",
    "model.compile(optimizer='nadam',loss='MSE',metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 450 samples, validate on 100 samples\n",
      "Epoch 1/100\n",
      "450/450 [==============================] - 24s 54ms/sample - loss: 7057.9654 - mean_absolute_error: 68.4795 - mean_squared_error: 7057.9648 - val_loss: 18215.6480 - val_mean_absolute_error: 127.3737 - val_mean_squared_error: 18215.6484\n",
      "Epoch 2/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 2017.1509 - mean_absolute_error: 38.4756 - mean_squared_error: 2017.1509 - val_loss: 18515.0477 - val_mean_absolute_error: 128.5724 - val_mean_squared_error: 18515.0469\n",
      "Epoch 3/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 1228.5999 - mean_absolute_error: 28.6835 - mean_squared_error: 1228.5997 - val_loss: 18601.0215 - val_mean_absolute_error: 128.9926 - val_mean_squared_error: 18601.0195\n",
      "Epoch 4/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 707.0131 - mean_absolute_error: 20.7273 - mean_squared_error: 707.0131 - val_loss: 17722.3455 - val_mean_absolute_error: 125.5326 - val_mean_squared_error: 17722.3457\n",
      "Epoch 5/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 568.9608 - mean_absolute_error: 18.2488 - mean_squared_error: 568.9608 - val_loss: 17459.4881 - val_mean_absolute_error: 124.4883 - val_mean_squared_error: 17459.4883\n",
      "Epoch 6/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 368.7650 - mean_absolute_error: 15.1415 - mean_squared_error: 368.7651 - val_loss: 16984.1572 - val_mean_absolute_error: 122.5255 - val_mean_squared_error: 16984.1582\n",
      "Epoch 7/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 328.3036 - mean_absolute_error: 13.7090 - mean_squared_error: 328.3036 - val_loss: 17167.5762 - val_mean_absolute_error: 123.2998 - val_mean_squared_error: 17167.5742\n",
      "Epoch 8/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 236.9241 - mean_absolute_error: 11.6564 - mean_squared_error: 236.9241 - val_loss: 16849.2850 - val_mean_absolute_error: 122.2960 - val_mean_squared_error: 16849.2852\n",
      "Epoch 9/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 261.2351 - mean_absolute_error: 12.6316 - mean_squared_error: 261.2350 - val_loss: 14889.1732 - val_mean_absolute_error: 113.9662 - val_mean_squared_error: 14889.1729\n",
      "Epoch 10/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 261.2932 - mean_absolute_error: 12.1957 - mean_squared_error: 261.2932 - val_loss: 14750.3297 - val_mean_absolute_error: 113.6799 - val_mean_squared_error: 14750.3301\n",
      "Epoch 11/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 201.7420 - mean_absolute_error: 10.7802 - mean_squared_error: 201.7420 - val_loss: 11519.4260 - val_mean_absolute_error: 98.7226 - val_mean_squared_error: 11519.4258\n",
      "Epoch 12/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 131.0748 - mean_absolute_error: 8.6248 - mean_squared_error: 131.0748 - val_loss: 11253.6139 - val_mean_absolute_error: 98.1086 - val_mean_squared_error: 11253.6133\n",
      "Epoch 13/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 178.7857 - mean_absolute_error: 10.0483 - mean_squared_error: 178.7857 - val_loss: 10011.8066 - val_mean_absolute_error: 91.5851 - val_mean_squared_error: 10011.8066\n",
      "Epoch 14/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 111.8779 - mean_absolute_error: 8.0298 - mean_squared_error: 111.8779 - val_loss: 8220.9179 - val_mean_absolute_error: 82.0869 - val_mean_squared_error: 8220.9180\n",
      "Epoch 15/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 125.9232 - mean_absolute_error: 8.2318 - mean_squared_error: 125.9232 - val_loss: 5654.8900 - val_mean_absolute_error: 63.7772 - val_mean_squared_error: 5654.8901\n",
      "Epoch 16/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 109.4281 - mean_absolute_error: 7.4592 - mean_squared_error: 109.4281 - val_loss: 6420.0926 - val_mean_absolute_error: 72.1592 - val_mean_squared_error: 6420.0923\n",
      "Epoch 17/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 81.3103 - mean_absolute_error: 6.5966 - mean_squared_error: 81.3103 - val_loss: 4357.8313 - val_mean_absolute_error: 56.8919 - val_mean_squared_error: 4357.8311\n",
      "Epoch 18/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 79.1003 - mean_absolute_error: 6.5065 - mean_squared_error: 79.1003 - val_loss: 4196.3003 - val_mean_absolute_error: 56.3821 - val_mean_squared_error: 4196.3003\n",
      "Epoch 19/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 79.1926 - mean_absolute_error: 6.5172 - mean_squared_error: 79.1926 - val_loss: 2773.6722 - val_mean_absolute_error: 42.1690 - val_mean_squared_error: 2773.6721\n",
      "Epoch 20/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 91.5319 - mean_absolute_error: 7.2007 - mean_squared_error: 91.5319 - val_loss: 1963.6422 - val_mean_absolute_error: 35.0780 - val_mean_squared_error: 1963.6422\n",
      "Epoch 21/100\n",
      "450/450 [==============================] - 4s 8ms/sample - loss: 79.2233 - mean_absolute_error: 6.4956 - mean_squared_error: 79.2233 - val_loss: 1274.9377 - val_mean_absolute_error: 28.1257 - val_mean_squared_error: 1274.9376\n",
      "Epoch 22/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 62.7313 - mean_absolute_error: 5.6584 - mean_squared_error: 62.7313 - val_loss: 2002.1082 - val_mean_absolute_error: 36.1389 - val_mean_squared_error: 2002.1082\n",
      "Epoch 23/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 76.5402 - mean_absolute_error: 6.3291 - mean_squared_error: 76.5402 - val_loss: 1108.8876 - val_mean_absolute_error: 25.5617 - val_mean_squared_error: 1108.8877\n",
      "Epoch 24/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 68.5165 - mean_absolute_error: 5.8827 - mean_squared_error: 68.5165 - val_loss: 732.7354 - val_mean_absolute_error: 21.5518 - val_mean_squared_error: 732.7354\n",
      "Epoch 25/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 54.6433 - mean_absolute_error: 5.3040 - mean_squared_error: 54.6433 - val_loss: 703.2838 - val_mean_absolute_error: 21.1899 - val_mean_squared_error: 703.2838\n",
      "Epoch 26/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 53.7531 - mean_absolute_error: 5.3523 - mean_squared_error: 53.7531 - val_loss: 609.5483 - val_mean_absolute_error: 19.5349 - val_mean_squared_error: 609.5483\n",
      "Epoch 27/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 55.0436 - mean_absolute_error: 5.4390 - mean_squared_error: 55.0436 - val_loss: 620.7533 - val_mean_absolute_error: 20.3735 - val_mean_squared_error: 620.7534\n",
      "Epoch 28/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 67.2710 - mean_absolute_error: 5.9967 - mean_squared_error: 67.2710 - val_loss: 574.1002 - val_mean_absolute_error: 18.7106 - val_mean_squared_error: 574.1003\n",
      "Epoch 29/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 68.2526 - mean_absolute_error: 6.2264 - mean_squared_error: 68.2526 - val_loss: 727.9287 - val_mean_absolute_error: 20.9172 - val_mean_squared_error: 727.9286\n",
      "Epoch 30/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 51.1708 - mean_absolute_error: 5.1391 - mean_squared_error: 51.1708 - val_loss: 616.5183 - val_mean_absolute_error: 20.0193 - val_mean_squared_error: 616.5183\n",
      "Epoch 31/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 55.4507 - mean_absolute_error: 5.6298 - mean_squared_error: 55.4507 - val_loss: 476.7099 - val_mean_absolute_error: 17.9911 - val_mean_squared_error: 476.7099\n",
      "Epoch 32/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 47.2998 - mean_absolute_error: 4.9845 - mean_squared_error: 47.2998 - val_loss: 532.4404 - val_mean_absolute_error: 20.4712 - val_mean_squared_error: 532.4405\n",
      "Epoch 33/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 54.0600 - mean_absolute_error: 5.4183 - mean_squared_error: 54.0600 - val_loss: 359.2399 - val_mean_absolute_error: 15.6528 - val_mean_squared_error: 359.2399\n",
      "Epoch 34/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 41.9560 - mean_absolute_error: 4.5575 - mean_squared_error: 41.9560 - val_loss: 364.9108 - val_mean_absolute_error: 16.0739 - val_mean_squared_error: 364.9108\n",
      "Epoch 35/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 41.0463 - mean_absolute_error: 4.4887 - mean_squared_error: 41.0463 - val_loss: 376.6919 - val_mean_absolute_error: 16.7748 - val_mean_squared_error: 376.6919\n",
      "Epoch 36/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 33.2473 - mean_absolute_error: 4.0812 - mean_squared_error: 33.2473 - val_loss: 334.8976 - val_mean_absolute_error: 15.2135 - val_mean_squared_error: 334.8976\n",
      "Epoch 37/100\n",
      "450/450 [==============================] - 4s 8ms/sample - loss: 44.9264 - mean_absolute_error: 4.8548 - mean_squared_error: 44.9264 - val_loss: 319.6143 - val_mean_absolute_error: 14.5883 - val_mean_squared_error: 319.6143\n",
      "Epoch 38/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 38.9919 - mean_absolute_error: 4.3671 - mean_squared_error: 38.9919 - val_loss: 383.4943 - val_mean_absolute_error: 16.7382 - val_mean_squared_error: 383.4943\n",
      "Epoch 39/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 55.4152 - mean_absolute_error: 5.4605 - mean_squared_error: 55.4152 - val_loss: 446.4585 - val_mean_absolute_error: 18.5776 - val_mean_squared_error: 446.4586\n",
      "Epoch 40/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 34.3478 - mean_absolute_error: 4.1675 - mean_squared_error: 34.3478 - val_loss: 349.7821 - val_mean_absolute_error: 15.2402 - val_mean_squared_error: 349.7821\n",
      "Epoch 41/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 38.7572 - mean_absolute_error: 4.6078 - mean_squared_error: 38.7572 - val_loss: 351.0831 - val_mean_absolute_error: 15.6875 - val_mean_squared_error: 351.0831\n",
      "Epoch 42/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 39.9056 - mean_absolute_error: 4.5048 - mean_squared_error: 39.9056 - val_loss: 377.3731 - val_mean_absolute_error: 15.9721 - val_mean_squared_error: 377.3730\n",
      "Epoch 43/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 26.8299 - mean_absolute_error: 3.6716 - mean_squared_error: 26.8299 - val_loss: 345.8321 - val_mean_absolute_error: 15.9021 - val_mean_squared_error: 345.8321\n",
      "Epoch 44/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 28.7164 - mean_absolute_error: 3.6745 - mean_squared_error: 28.7164 - val_loss: 454.8615 - val_mean_absolute_error: 18.1602 - val_mean_squared_error: 454.8615\n",
      "Epoch 45/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 29.2548 - mean_absolute_error: 3.9330 - mean_squared_error: 29.2548 - val_loss: 402.6282 - val_mean_absolute_error: 16.1349 - val_mean_squared_error: 402.6281\n",
      "Epoch 46/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 37.1992 - mean_absolute_error: 4.5650 - mean_squared_error: 37.1992 - val_loss: 369.8073 - val_mean_absolute_error: 16.1332 - val_mean_squared_error: 369.8073\n",
      "Epoch 47/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 29.2232 - mean_absolute_error: 4.1121 - mean_squared_error: 29.2232 - val_loss: 368.3999 - val_mean_absolute_error: 15.5091 - val_mean_squared_error: 368.3998\n",
      "Epoch 48/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 36.0294 - mean_absolute_error: 4.3131 - mean_squared_error: 36.0294 - val_loss: 372.2305 - val_mean_absolute_error: 16.7070 - val_mean_squared_error: 372.2306\n",
      "Epoch 49/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 25.0072 - mean_absolute_error: 3.6904 - mean_squared_error: 25.0072 - val_loss: 476.3770 - val_mean_absolute_error: 17.9657 - val_mean_squared_error: 476.3770\n",
      "Epoch 50/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 34.8126 - mean_absolute_error: 4.2897 - mean_squared_error: 34.8125 - val_loss: 334.6248 - val_mean_absolute_error: 15.0099 - val_mean_squared_error: 334.6248\n",
      "Epoch 51/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 30.5244 - mean_absolute_error: 4.1986 - mean_squared_error: 30.5244 - val_loss: 331.0127 - val_mean_absolute_error: 15.1161 - val_mean_squared_error: 331.0127\n",
      "Epoch 52/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 26.5979 - mean_absolute_error: 3.8275 - mean_squared_error: 26.5979 - val_loss: 289.1302 - val_mean_absolute_error: 14.1637 - val_mean_squared_error: 289.1302\n",
      "Epoch 53/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 26.7256 - mean_absolute_error: 3.8513 - mean_squared_error: 26.7256 - val_loss: 362.5290 - val_mean_absolute_error: 16.1376 - val_mean_squared_error: 362.5291\n",
      "Epoch 54/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 24.1420 - mean_absolute_error: 3.6965 - mean_squared_error: 24.1420 - val_loss: 411.1544 - val_mean_absolute_error: 17.5739 - val_mean_squared_error: 411.1544\n",
      "Epoch 55/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 21.6118 - mean_absolute_error: 3.3406 - mean_squared_error: 21.6118 - val_loss: 411.0027 - val_mean_absolute_error: 17.3387 - val_mean_squared_error: 411.0027\n",
      "Epoch 56/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 22.9644 - mean_absolute_error: 3.5069 - mean_squared_error: 22.9644 - val_loss: 361.9193 - val_mean_absolute_error: 16.6712 - val_mean_squared_error: 361.9193\n",
      "Epoch 57/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 29.5312 - mean_absolute_error: 4.0752 - mean_squared_error: 29.5312 - val_loss: 312.7532 - val_mean_absolute_error: 14.7216 - val_mean_squared_error: 312.7532\n",
      "Epoch 58/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 22.7903 - mean_absolute_error: 3.4817 - mean_squared_error: 22.7903 - val_loss: 453.3487 - val_mean_absolute_error: 16.7681 - val_mean_squared_error: 453.3487\n",
      "Epoch 59/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 31.3350 - mean_absolute_error: 4.3258 - mean_squared_error: 31.3350 - val_loss: 339.1116 - val_mean_absolute_error: 15.2898 - val_mean_squared_error: 339.1116\n",
      "Epoch 60/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 27.6176 - mean_absolute_error: 4.1015 - mean_squared_error: 27.6175 - val_loss: 310.6929 - val_mean_absolute_error: 14.5701 - val_mean_squared_error: 310.6929\n",
      "Epoch 61/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 28.2915 - mean_absolute_error: 4.1482 - mean_squared_error: 28.2915 - val_loss: 268.8123 - val_mean_absolute_error: 13.6134 - val_mean_squared_error: 268.8123\n",
      "Epoch 62/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 23.8741 - mean_absolute_error: 3.6954 - mean_squared_error: 23.8741 - val_loss: 299.6052 - val_mean_absolute_error: 14.6275 - val_mean_squared_error: 299.6052\n",
      "Epoch 63/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 24.7609 - mean_absolute_error: 3.7331 - mean_squared_error: 24.7609 - val_loss: 314.7591 - val_mean_absolute_error: 14.0482 - val_mean_squared_error: 314.7591\n",
      "Epoch 64/100\n",
      "450/450 [==============================] - 4s 8ms/sample - loss: 25.0865 - mean_absolute_error: 3.7526 - mean_squared_error: 25.0865 - val_loss: 449.7176 - val_mean_absolute_error: 17.6232 - val_mean_squared_error: 449.7175\n",
      "Epoch 65/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 17.8028 - mean_absolute_error: 3.1090 - mean_squared_error: 17.8028 - val_loss: 463.3336 - val_mean_absolute_error: 17.4677 - val_mean_squared_error: 463.3336\n",
      "Epoch 66/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 21.3532 - mean_absolute_error: 3.5755 - mean_squared_error: 21.3532 - val_loss: 430.5773 - val_mean_absolute_error: 17.2819 - val_mean_squared_error: 430.5773\n",
      "Epoch 67/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 18.8231 - mean_absolute_error: 3.2673 - mean_squared_error: 18.8231 - val_loss: 372.3760 - val_mean_absolute_error: 15.3274 - val_mean_squared_error: 372.3760\n",
      "Epoch 68/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 19.7765 - mean_absolute_error: 3.3759 - mean_squared_error: 19.7765 - val_loss: 312.4407 - val_mean_absolute_error: 15.1273 - val_mean_squared_error: 312.4407\n",
      "Epoch 69/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 19.0712 - mean_absolute_error: 3.2465 - mean_squared_error: 19.0712 - val_loss: 265.5384 - val_mean_absolute_error: 13.8448 - val_mean_squared_error: 265.5384\n",
      "Epoch 70/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 15.4026 - mean_absolute_error: 3.1131 - mean_squared_error: 15.4026 - val_loss: 298.1034 - val_mean_absolute_error: 14.7866 - val_mean_squared_error: 298.1034\n",
      "Epoch 71/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 17.5418 - mean_absolute_error: 3.2839 - mean_squared_error: 17.5418 - val_loss: 379.1139 - val_mean_absolute_error: 16.6059 - val_mean_squared_error: 379.1139\n",
      "Epoch 72/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 25.9178 - mean_absolute_error: 3.9217 - mean_squared_error: 25.9178 - val_loss: 349.8102 - val_mean_absolute_error: 15.4976 - val_mean_squared_error: 349.8102\n",
      "Epoch 73/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 15.3482 - mean_absolute_error: 2.9422 - mean_squared_error: 15.3482 - val_loss: 304.4225 - val_mean_absolute_error: 15.0069 - val_mean_squared_error: 304.4225\n",
      "Epoch 74/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 20.9079 - mean_absolute_error: 3.4021 - mean_squared_error: 20.9079 - val_loss: 342.6656 - val_mean_absolute_error: 16.1900 - val_mean_squared_error: 342.6656\n",
      "Epoch 75/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 14.3801 - mean_absolute_error: 2.9147 - mean_squared_error: 14.3801 - val_loss: 320.2563 - val_mean_absolute_error: 15.1531 - val_mean_squared_error: 320.2563\n",
      "Epoch 76/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 17.5527 - mean_absolute_error: 3.2884 - mean_squared_error: 17.5527 - val_loss: 230.3452 - val_mean_absolute_error: 12.5616 - val_mean_squared_error: 230.3452\n",
      "Epoch 77/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 16.4210 - mean_absolute_error: 3.1118 - mean_squared_error: 16.4210 - val_loss: 300.6786 - val_mean_absolute_error: 15.0430 - val_mean_squared_error: 300.6786\n",
      "Epoch 78/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 22.1754 - mean_absolute_error: 3.5224 - mean_squared_error: 22.1754 - val_loss: 287.0842 - val_mean_absolute_error: 14.0508 - val_mean_squared_error: 287.0841\n",
      "Epoch 79/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 14.5044 - mean_absolute_error: 3.0079 - mean_squared_error: 14.5044 - val_loss: 300.5000 - val_mean_absolute_error: 14.4988 - val_mean_squared_error: 300.5000\n",
      "Epoch 80/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 11.9658 - mean_absolute_error: 2.6794 - mean_squared_error: 11.9658 - val_loss: 261.8265 - val_mean_absolute_error: 13.1957 - val_mean_squared_error: 261.8265\n",
      "Epoch 81/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 12.2563 - mean_absolute_error: 2.7216 - mean_squared_error: 12.2563 - val_loss: 257.8304 - val_mean_absolute_error: 13.5303 - val_mean_squared_error: 257.8304\n",
      "Epoch 82/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 15.3209 - mean_absolute_error: 3.0962 - mean_squared_error: 15.3209 - val_loss: 306.2139 - val_mean_absolute_error: 14.8604 - val_mean_squared_error: 306.2139\n",
      "Epoch 83/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 13.1957 - mean_absolute_error: 2.8030 - mean_squared_error: 13.1957 - val_loss: 325.5165 - val_mean_absolute_error: 15.0455 - val_mean_squared_error: 325.5165\n",
      "Epoch 84/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 15.7408 - mean_absolute_error: 3.0932 - mean_squared_error: 15.7408 - val_loss: 347.7546 - val_mean_absolute_error: 15.9527 - val_mean_squared_error: 347.7546\n",
      "Epoch 85/100\n",
      "450/450 [==============================] - 3s 8ms/sample - loss: 15.7275 - mean_absolute_error: 3.1975 - mean_squared_error: 15.7275 - val_loss: 263.4590 - val_mean_absolute_error: 13.7455 - val_mean_squared_error: 263.4590\n",
      "Epoch 86/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 17.1387 - mean_absolute_error: 3.2327 - mean_squared_error: 17.1387 - val_loss: 313.4207 - val_mean_absolute_error: 14.6072 - val_mean_squared_error: 313.4207\n",
      "Epoch 87/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 17.0015 - mean_absolute_error: 3.2549 - mean_squared_error: 17.0015 - val_loss: 252.4043 - val_mean_absolute_error: 13.3340 - val_mean_squared_error: 252.4043\n",
      "Epoch 88/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 11.3672 - mean_absolute_error: 2.5924 - mean_squared_error: 11.3672 - val_loss: 283.4162 - val_mean_absolute_error: 13.0862 - val_mean_squared_error: 283.4163\n",
      "Epoch 89/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 29.6560 - mean_absolute_error: 4.3121 - mean_squared_error: 29.6560 - val_loss: 290.7133 - val_mean_absolute_error: 14.0999 - val_mean_squared_error: 290.7133\n",
      "Epoch 90/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 14.7818 - mean_absolute_error: 2.9173 - mean_squared_error: 14.7818 - val_loss: 351.9425 - val_mean_absolute_error: 15.9986 - val_mean_squared_error: 351.9425\n",
      "Epoch 91/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 14.3819 - mean_absolute_error: 2.9762 - mean_squared_error: 14.3819 - val_loss: 235.9733 - val_mean_absolute_error: 12.9586 - val_mean_squared_error: 235.9733\n",
      "Epoch 92/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 17.5467 - mean_absolute_error: 3.2285 - mean_squared_error: 17.5467 - val_loss: 381.0148 - val_mean_absolute_error: 16.5804 - val_mean_squared_error: 381.0148\n",
      "Epoch 93/100\n",
      "450/450 [==============================] - 3s 6ms/sample - loss: 16.8018 - mean_absolute_error: 3.2004 - mean_squared_error: 16.8018 - val_loss: 292.2579 - val_mean_absolute_error: 13.6236 - val_mean_squared_error: 292.2579\n",
      "Epoch 94/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 12.6836 - mean_absolute_error: 2.7681 - mean_squared_error: 12.6836 - val_loss: 402.6474 - val_mean_absolute_error: 14.9287 - val_mean_squared_error: 402.6474\n",
      "Epoch 95/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 14.5275 - mean_absolute_error: 2.7683 - mean_squared_error: 14.5275 - val_loss: 329.1856 - val_mean_absolute_error: 14.8485 - val_mean_squared_error: 329.1856\n",
      "Epoch 96/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 12.7877 - mean_absolute_error: 2.8000 - mean_squared_error: 12.7877 - val_loss: 291.1996 - val_mean_absolute_error: 14.1625 - val_mean_squared_error: 291.1996\n",
      "Epoch 97/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 10.8095 - mean_absolute_error: 2.5524 - mean_squared_error: 10.8095 - val_loss: 263.1768 - val_mean_absolute_error: 13.9765 - val_mean_squared_error: 263.1768\n",
      "Epoch 98/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 12.0311 - mean_absolute_error: 2.7231 - mean_squared_error: 12.0311 - val_loss: 291.8134 - val_mean_absolute_error: 14.6352 - val_mean_squared_error: 291.8134\n",
      "Epoch 99/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 14.6747 - mean_absolute_error: 2.9055 - mean_squared_error: 14.6747 - val_loss: 534.9776 - val_mean_absolute_error: 17.9355 - val_mean_squared_error: 534.9776\n",
      "Epoch 100/100\n",
      "450/450 [==============================] - 3s 7ms/sample - loss: 13.6044 - mean_absolute_error: 2.8593 - mean_squared_error: 13.6044 - val_loss: 307.1735 - val_mean_absolute_error: 15.0834 - val_mean_squared_error: 307.1736\n"
     ]
    }
   ],
   "source": [
    "# train the model using a mini batch size of 100 images and 50 epochs\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=20,validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Evaluate on test data\n",
      "550/550 [==============================] - 3s 5ms/sample - loss: 69.1333 - mean_absolute_error: 5.3561 - mean_squared_error: 69.1333\n",
      "test loss, test mse: [69.13332479650325, 5.356071, 69.13332]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the test data using `evaluate`\n",
    "print('\\n# Evaluate on test data')\n",
    "results = model.evaluate(X_test, y_test, batch_size=100)\n",
    "print('test loss, test mse:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/api/_v1/keras/layers/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tab:blue'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# we already handled the x-label with ax1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0max2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabelcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mse'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2e95f748>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy and loss as a function of the epochs\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax1.set_xlabel('epochs')\n",
    "ax1.set_ylabel('loss', color=color)\n",
    "ax1.plot(history.history['loss'], color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('mse', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(history.history['mse'], color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual : 107.0 -- Pres : [109.14441]\n",
      "Actual : 107.6 -- Pres : [109.74423]\n",
      "Actual : 107.6 -- Pres : [107.86649]\n",
      "Actual : 107.6 -- Pres : [107.044975]\n",
      "Actual : 107.6 -- Pres : [107.71019]\n",
      "Actual : 107.6 -- Pres : [108.222015]\n",
      "Actual : 107.6 -- Pres : [108.60607]\n",
      "Actual : 107.6 -- Pres : [106.16433]\n",
      "Actual : 107.6 -- Pres : [108.107834]\n",
      "Actual : 107.6 -- Pres : [105.370674]\n",
      "Actual : 107.6 -- Pres : [106.39687]\n",
      "Actual : 107.6 -- Pres : [106.042175]\n",
      "Actual : 107.6 -- Pres : [106.27174]\n",
      "Actual : 107.6 -- Pres : [106.18567]\n",
      "Actual : 107.6 -- Pres : [105.82971]\n",
      "Actual : 107.6 -- Pres : [107.30092]\n",
      "Actual : 107.6 -- Pres : [107.71571]\n",
      "Actual : 107.6 -- Pres : [108.96794]\n",
      "Actual : 107.6 -- Pres : [109.32758]\n",
      "Actual : 107.6 -- Pres : [106.8824]\n",
      "Actual : 107.6 -- Pres : [107.69978]\n",
      "Actual : 107.6 -- Pres : [106.090675]\n",
      "Actual : 107.6 -- Pres : [108.41795]\n",
      "Actual : 109.0 -- Pres : [110.19004]\n",
      "Actual : 109.0 -- Pres : [110.74855]\n",
      "Actual : 103.0 -- Pres : [100.875854]\n",
      "Actual : 93.0 -- Pres : [92.41871]\n",
      "Actual : 86.0 -- Pres : [87.49726]\n",
      "Actual : 82.0 -- Pres : [82.2595]\n",
      "Actual : 78.0 -- Pres : [79.00188]\n",
      "Actual : 76.0 -- Pres : [73.63524]\n",
      "Actual : 67.0 -- Pres : [68.27771]\n",
      "Actual : 59.0 -- Pres : [61.291115]\n",
      "Actual : 53.0 -- Pres : [58.779686]\n",
      "Actual : 51.0 -- Pres : [56.50554]\n",
      "Actual : 46.0 -- Pres : [53.42141]\n",
      "Actual : 42.0 -- Pres : [45.26347]\n",
      "Actual : 40.0 -- Pres : [41.756577]\n",
      "Actual : 36.0 -- Pres : [36.121826]\n",
      "Actual : 34.0 -- Pres : [37.434742]\n",
      "Actual : 33.0 -- Pres : [34.805435]\n",
      "Actual : 32.0 -- Pres : [37.314053]\n",
      "Actual : 29.0 -- Pres : [29.56098]\n",
      "Actual : 29.6 -- Pres : [28.68404]\n",
      "Actual : 27.0 -- Pres : [23.437582]\n",
      "Actual : 27.1 -- Pres : [21.997423]\n",
      "Actual : 27.1 -- Pres : [30.940506]\n",
      "Actual : 27.1 -- Pres : [31.844141]\n",
      "Actual : 27.1 -- Pres : [27.320633]\n",
      "Actual : 23.0 -- Pres : [24.94331]\n",
      "Actual : 21.0 -- Pres : [20.972443]\n",
      "Actual : 16.0 -- Pres : [20.314821]\n",
      "Actual : 14.0 -- Pres : [16.8758]\n",
      "Actual : 14.0 -- Pres : [18.76866]\n",
      "Actual : 19.0 -- Pres : [21.38512]\n",
      "Actual : 17.0 -- Pres : [14.330173]\n",
      "Actual : 19.0 -- Pres : [15.722163]\n",
      "Actual : 15.0 -- Pres : [14.127177]\n",
      "Actual : 15.1 -- Pres : [14.68525]\n",
      "Actual : 15.1 -- Pres : [14.6735735]\n",
      "Actual : 15.1 -- Pres : [17.793585]\n",
      "Actual : 15.1 -- Pres : [16.597534]\n",
      "Actual : 13.0 -- Pres : [14.322061]\n",
      "Actual : 13.4 -- Pres : [13.907788]\n",
      "Actual : 13.4 -- Pres : [13.766308]\n",
      "Actual : 13.4 -- Pres : [13.663371]\n",
      "Actual : 13.4 -- Pres : [15.613751]\n",
      "Actual : 13.4 -- Pres : [14.5868845]\n",
      "Actual : 13.4 -- Pres : [14.63409]\n",
      "Actual : 11.0 -- Pres : [8.951251]\n",
      "Actual : 11.8 -- Pres : [10.037223]\n",
      "Actual : 11.8 -- Pres : [11.921062]\n",
      "Actual : 11.8 -- Pres : [11.774654]\n",
      "Actual : 16.0 -- Pres : [16.504642]\n",
      "Actual : 14.0 -- Pres : [12.929246]\n",
      "Actual : 14.0 -- Pres : [13.258896]\n",
      "Actual : 13.0 -- Pres : [12.866634]\n",
      "Actual : 13.6 -- Pres : [13.875698]\n",
      "Actual : 13.6 -- Pres : [13.093074]\n",
      "Actual : 18.0 -- Pres : [15.762158]\n",
      "Actual : 18.1 -- Pres : [16.646408]\n",
      "Actual : 18.1 -- Pres : [14.906796]\n",
      "Actual : 18.1 -- Pres : [19.67423]\n",
      "Actual : 18.1 -- Pres : [20.676788]\n",
      "Actual : 21.0 -- Pres : [20.726532]\n",
      "Actual : 21.0 -- Pres : [25.370115]\n",
      "Actual : 21.0 -- Pres : [24.60816]\n",
      "Actual : 21.0 -- Pres : [25.014727]\n",
      "Actual : 24.0 -- Pres : [27.721695]\n",
      "Actual : 24.7 -- Pres : [28.276772]\n",
      "Actual : 26.0 -- Pres : [26.133345]\n",
      "Actual : 26.1 -- Pres : [27.36389]\n",
      "Actual : 26.0 -- Pres : [32.330387]\n",
      "Actual : 26.7 -- Pres : [34.31477]\n",
      "Actual : 30.0 -- Pres : [34.223763]\n",
      "Actual : 30.4 -- Pres : [34.629448]\n",
      "Actual : 33.0 -- Pres : [39.87751]\n",
      "Actual : 33.3 -- Pres : [37.67828]\n",
      "Actual : 36.0 -- Pres : [40.046276]\n",
      "Actual : 36.2 -- Pres : [39.398758]\n",
      "Actual : 39.0 -- Pres : [44.613625]\n",
      "Actual : 39.0 -- Pres : [43.870327]\n",
      "Actual : 39.0 -- Pres : [42.332348]\n",
      "Actual : 41.0 -- Pres : [49.60672]\n",
      "Actual : 46.0 -- Pres : [53.750988]\n",
      "Actual : 48.0 -- Pres : [58.16825]\n",
      "Actual : 50.0 -- Pres : [53.34181]\n",
      "Actual : 54.0 -- Pres : [55.463726]\n",
      "Actual : 57.0 -- Pres : [58.15875]\n",
      "Actual : 61.0 -- Pres : [62.800694]\n",
      "Actual : 61.0 -- Pres : [64.04804]\n",
      "Actual : 61.6 -- Pres : [63.11606]\n",
      "Actual : 61.6 -- Pres : [68.297455]\n",
      "Actual : 69.0 -- Pres : [70.98432]\n",
      "Actual : 73.0 -- Pres : [74.68089]\n",
      "Actual : 77.0 -- Pres : [83.6912]\n",
      "Actual : 78.0 -- Pres : [81.481514]\n",
      "Actual : 81.0 -- Pres : [83.78731]\n",
      "Actual : 86.0 -- Pres : [87.395256]\n",
      "Actual : 91.0 -- Pres : [94.7982]\n",
      "Actual : 95.0 -- Pres : [97.70564]\n",
      "Actual : 100.0 -- Pres : [104.60251]\n",
      "Actual : 104.0 -- Pres : [110.924286]\n",
      "Actual : 108.0 -- Pres : [114.64675]\n",
      "Actual : 109.0 -- Pres : [114.127205]\n",
      "Actual : 109.0 -- Pres : [114.230934]\n",
      "Actual : 115.0 -- Pres : [119.39734]\n",
      "Actual : 115.2 -- Pres : [121.57142]\n",
      "Actual : 115.2 -- Pres : [120.37246]\n",
      "Actual : 115.2 -- Pres : [124.951645]\n",
      "Actual : 117.0 -- Pres : [118.28403]\n",
      "Actual : 117.5 -- Pres : [117.61236]\n",
      "Actual : 121.0 -- Pres : [121.135216]\n",
      "Actual : 121.3 -- Pres : [123.05521]\n",
      "Actual : 125.0 -- Pres : [129.89735]\n",
      "Actual : 131.0 -- Pres : [133.2472]\n",
      "Actual : 133.0 -- Pres : [134.32756]\n",
      "Actual : 136.0 -- Pres : [138.16382]\n",
      "Actual : 140.0 -- Pres : [143.09607]\n",
      "Actual : 143.0 -- Pres : [144.12935]\n",
      "Actual : 147.0 -- Pres : [153.3438]\n",
      "Actual : 150.0 -- Pres : [152.02715]\n",
      "Actual : 153.0 -- Pres : [157.60367]\n",
      "Actual : 157.0 -- Pres : [163.58366]\n",
      "Actual : 160.0 -- Pres : [162.43466]\n",
      "Actual : 166.0 -- Pres : [168.38979]\n",
      "Actual : 169.0 -- Pres : [170.50539]\n",
      "Actual : 173.0 -- Pres : [176.11038]\n",
      "Actual : 178.0 -- Pres : [181.85297]\n",
      "Actual : 178.6 -- Pres : [180.73521]\n",
      "Actual : 178.6 -- Pres : [186.24146]\n",
      "Actual : 183.0 -- Pres : [190.10954]\n",
      "Actual : 186.0 -- Pres : [189.61252]\n",
      "Actual : 188.0 -- Pres : [188.82741]\n",
      "Actual : 192.0 -- Pres : [193.22992]\n",
      "Actual : 195.0 -- Pres : [201.1371]\n",
      "Actual : 195.3 -- Pres : [201.12938]\n",
      "Actual : 195.3 -- Pres : [196.31337]\n",
      "Actual : 198.0 -- Pres : [201.81892]\n",
      "Actual : 201.0 -- Pres : [199.97354]\n",
      "Actual : 205.0 -- Pres : [201.7922]\n",
      "Actual : 208.0 -- Pres : [206.30505]\n",
      "Actual : 211.0 -- Pres : [209.90816]\n",
      "Actual : 212.0 -- Pres : [209.88974]\n",
      "Actual : 209.0 -- Pres : [215.58748]\n",
      "Actual : 208.0 -- Pres : [217.79533]\n",
      "Actual : 208.0 -- Pres : [210.43411]\n",
      "Actual : 205.0 -- Pres : [209.46317]\n",
      "Actual : 198.0 -- Pres : [204.97433]\n",
      "Actual : 198.2 -- Pres : [201.8508]\n",
      "Actual : 187.0 -- Pres : [190.95813]\n",
      "Actual : 184.0 -- Pres : [189.21735]\n",
      "Actual : 184.0 -- Pres : [190.96283]\n",
      "Actual : 186.0 -- Pres : [195.09752]\n",
      "Actual : 194.0 -- Pres : [189.52531]\n",
      "Actual : 186.0 -- Pres : [188.01852]\n",
      "Actual : 175.0 -- Pres : [182.74358]\n",
      "Actual : 170.0 -- Pres : [174.19617]\n",
      "Actual : 168.0 -- Pres : [173.46321]\n",
      "Actual : 169.0 -- Pres : [169.72343]\n",
      "Actual : 169.3 -- Pres : [169.28247]\n",
      "Actual : 169.3 -- Pres : [169.32079]\n",
      "Actual : 166.0 -- Pres : [165.36723]\n",
      "Actual : 158.0 -- Pres : [154.94812]\n",
      "Actual : 150.0 -- Pres : [151.94258]\n",
      "Actual : 146.0 -- Pres : [150.75645]\n",
      "Actual : 144.0 -- Pres : [151.12048]\n",
      "Actual : 147.0 -- Pres : [147.87816]\n",
      "Actual : 143.0 -- Pres : [138.8582]\n",
      "Actual : 138.0 -- Pres : [139.01907]\n",
      "Actual : 133.0 -- Pres : [134.63814]\n",
      "Actual : 133.8 -- Pres : [134.3918]\n",
      "Actual : 132.0 -- Pres : [130.70146]\n",
      "Actual : 128.0 -- Pres : [123.01902]\n",
      "Actual : 119.0 -- Pres : [112.680214]\n",
      "Actual : 116.0 -- Pres : [109.701645]\n",
      "Actual : 109.0 -- Pres : [105.7507]\n",
      "Actual : 107.0 -- Pres : [105.6973]\n",
      "Actual : 107.0 -- Pres : [104.01311]\n",
      "Actual : 102.0 -- Pres : [102.25379]\n",
      "Actual : 96.0 -- Pres : [95.76825]\n",
      "Actual : 94.0 -- Pres : [92.91335]\n",
      "Actual : 96.0 -- Pres : [96.95357]\n",
      "Actual : 96.0 -- Pres : [97.24443]\n",
      "Actual : 96.0 -- Pres : [95.95124]\n",
      "Actual : 96.0 -- Pres : [96.23803]\n",
      "Actual : 95.0 -- Pres : [97.21341]\n",
      "Actual : 95.3 -- Pres : [94.649796]\n",
      "Actual : 97.0 -- Pres : [94.97454]\n",
      "Actual : 99.0 -- Pres : [98.74015]\n",
      "Actual : 101.0 -- Pres : [99.36501]\n",
      "Actual : 103.0 -- Pres : [103.384254]\n",
      "Actual : 104.0 -- Pres : [105.66624]\n",
      "Actual : 104.9 -- Pres : [107.72439]\n",
      "Actual : 107.0 -- Pres : [108.29818]\n",
      "Actual : 112.0 -- Pres : [114.9463]\n",
      "Actual : 115.0 -- Pres : [117.94037]\n",
      "Actual : 119.0 -- Pres : [120.302124]\n",
      "Actual : 124.0 -- Pres : [128.67639]\n",
      "Actual : 124.0 -- Pres : [129.08774]\n",
      "Actual : 125.0 -- Pres : [129.04974]\n",
      "Actual : 125.5 -- Pres : [127.988495]\n",
      "Actual : 127.0 -- Pres : [131.06816]\n",
      "Actual : 127.7 -- Pres : [135.40591]\n",
      "Actual : 127.7 -- Pres : [132.18666]\n",
      "Actual : 127.7 -- Pres : [131.94775]\n",
      "Actual : 127.7 -- Pres : [135.74623]\n",
      "Actual : 127.7 -- Pres : [133.92706]\n",
      "Actual : 127.7 -- Pres : [132.75197]\n",
      "Actual : 127.7 -- Pres : [132.19362]\n",
      "Actual : 127.7 -- Pres : [133.86444]\n",
      "Actual : 127.7 -- Pres : [135.0493]\n",
      "Actual : 127.7 -- Pres : [130.8697]\n",
      "Actual : 127.7 -- Pres : [132.10016]\n",
      "Actual : 127.7 -- Pres : [131.26883]\n",
      "Actual : 127.7 -- Pres : [131.48782]\n",
      "Actual : 127.7 -- Pres : [133.17812]\n",
      "Actual : 127.7 -- Pres : [131.85771]\n",
      "Actual : 127.7 -- Pres : [133.82115]\n",
      "Actual : 129.0 -- Pres : [134.305]\n",
      "Actual : 129.9 -- Pres : [133.51892]\n",
      "Actual : 129.9 -- Pres : [133.65286]\n",
      "Actual : 129.9 -- Pres : [135.74773]\n",
      "Actual : 129.9 -- Pres : [134.0836]\n",
      "Actual : 132.0 -- Pres : [135.3898]\n",
      "Actual : 135.0 -- Pres : [135.15376]\n",
      "Actual : 137.0 -- Pres : [140.31477]\n",
      "Actual : 140.0 -- Pres : [143.03307]\n",
      "Actual : 142.0 -- Pres : [148.6958]\n",
      "Actual : 142.2 -- Pres : [149.32773]\n",
      "Actual : 142.2 -- Pres : [136.95894]\n",
      "Actual : 48.0 -- Pres : [55.967598]\n",
      "Actual : 48.0 -- Pres : [58.590214]\n",
      "Actual : 48.0 -- Pres : [53.731483]\n",
      "Actual : 48.0 -- Pres : [54.18266]\n",
      "Actual : 48.0 -- Pres : [54.48529]\n",
      "Actual : 48.0 -- Pres : [54.619045]\n",
      "Actual : 48.0 -- Pres : [55.799385]\n",
      "Actual : 48.0 -- Pres : [53.38992]\n",
      "Actual : 48.0 -- Pres : [55.66071]\n",
      "Actual : 48.0 -- Pres : [57.430305]\n",
      "Actual : 48.0 -- Pres : [53.44225]\n",
      "Actual : 48.0 -- Pres : [52.551506]\n",
      "Actual : 48.0 -- Pres : [52.596058]\n",
      "Actual : 48.0 -- Pres : [53.9985]\n",
      "Actual : 48.0 -- Pres : [53.274376]\n",
      "Actual : 48.0 -- Pres : [54.963486]\n",
      "Actual : 48.0 -- Pres : [54.74078]\n",
      "Actual : 48.0 -- Pres : [55.48768]\n",
      "Actual : 48.0 -- Pres : [56.174965]\n",
      "Actual : 48.0 -- Pres : [52.443825]\n",
      "Actual : 48.0 -- Pres : [50.513824]\n",
      "Actual : 48.0 -- Pres : [57.620758]\n",
      "Actual : 48.0 -- Pres : [52.728474]\n",
      "Actual : 48.0 -- Pres : [55.717014]\n",
      "Actual : 48.0 -- Pres : [53.46373]\n",
      "Actual : 43.0 -- Pres : [50.966908]\n",
      "Actual : 40.0 -- Pres : [47.152325]\n",
      "Actual : 36.0 -- Pres : [43.1928]\n",
      "Actual : 29.0 -- Pres : [32.380898]\n",
      "Actual : 20.0 -- Pres : [22.041357]\n",
      "Actual : 17.0 -- Pres : [16.078201]\n",
      "Actual : 7.0 -- Pres : [7.688104]\n",
      "Actual : 3.0 -- Pres : [0.1393266]\n",
      "Actual : 3.9 -- Pres : [-3.2641172]\n",
      "Actual : 0.0 -- Pres : [-14.020986]\n",
      "Actual : 0.0 -- Pres : [-6.0397906]\n",
      "Actual : 0.0 -- Pres : [-0.29732606]\n",
      "Actual : 0.0 -- Pres : [-3.6945696]\n",
      "Actual : 0.0 -- Pres : [-6.797293]\n",
      "Actual : 0.0 -- Pres : [-9.451401]\n",
      "Actual : 0.0 -- Pres : [-7.06182]\n",
      "Actual : 0.0 -- Pres : [-10.56816]\n",
      "Actual : 0.0 -- Pres : [-4.2706957]\n",
      "Actual : 0.0 -- Pres : [-1.8110538]\n",
      "Actual : 0.0 -- Pres : [2.4273622]\n",
      "Actual : 0.0 -- Pres : [1.1036384]\n",
      "Actual : 0.0 -- Pres : [-1.8498487]\n",
      "Actual : 0.0 -- Pres : [-0.9966953]\n",
      "Actual : 0.0 -- Pres : [0.7359843]\n",
      "Actual : 0.0 -- Pres : [1.0680559]\n",
      "Actual : 0.0 -- Pres : [-3.2409692]\n",
      "Actual : 6.0 -- Pres : [5.9155207]\n",
      "Actual : 12.0 -- Pres : [11.748633]\n",
      "Actual : 14.0 -- Pres : [16.20831]\n",
      "Actual : 19.0 -- Pres : [22.465797]\n",
      "Actual : 20.0 -- Pres : [26.291735]\n",
      "Actual : 20.4 -- Pres : [25.713581]\n",
      "Actual : 20.4 -- Pres : [28.899418]\n",
      "Actual : 28.0 -- Pres : [35.32222]\n",
      "Actual : 28.7 -- Pres : [35.894516]\n",
      "Actual : 33.0 -- Pres : [38.82404]\n",
      "Actual : 33.9 -- Pres : [39.778618]\n",
      "Actual : 39.0 -- Pres : [44.346317]\n",
      "Actual : 39.8 -- Pres : [45.761574]\n",
      "Actual : 44.0 -- Pres : [49.376022]\n",
      "Actual : 49.0 -- Pres : [53.388317]\n",
      "Actual : 51.0 -- Pres : [52.072945]\n",
      "Actual : 57.0 -- Pres : [54.66645]\n",
      "Actual : 58.0 -- Pres : [58.571026]\n",
      "Actual : 63.0 -- Pres : [64.26897]\n",
      "Actual : 64.0 -- Pres : [66.16263]\n",
      "Actual : 66.0 -- Pres : [67.664986]\n",
      "Actual : 66.1 -- Pres : [69.278175]\n",
      "Actual : 69.0 -- Pres : [72.08301]\n",
      "Actual : 72.0 -- Pres : [74.89851]\n",
      "Actual : 76.0 -- Pres : [77.14124]\n",
      "Actual : 75.0 -- Pres : [78.71843]\n",
      "Actual : 79.0 -- Pres : [84.79546]\n",
      "Actual : 83.0 -- Pres : [87.58654]\n",
      "Actual : 87.0 -- Pres : [88.20337]\n",
      "Actual : 88.0 -- Pres : [89.15959]\n",
      "Actual : 92.0 -- Pres : [93.49635]\n",
      "Actual : 96.0 -- Pres : [97.05766]\n",
      "Actual : 96.0 -- Pres : [97.38353]\n",
      "Actual : 103.0 -- Pres : [103.57006]\n",
      "Actual : 106.0 -- Pres : [106.385315]\n",
      "Actual : 110.0 -- Pres : [108.89054]\n",
      "Actual : 112.0 -- Pres : [114.097855]\n",
      "Actual : 112.3 -- Pres : [116.36412]\n",
      "Actual : 114.0 -- Pres : [116.307465]\n",
      "Actual : 117.0 -- Pres : [120.54088]\n",
      "Actual : 117.7 -- Pres : [122.76959]\n",
      "Actual : 129.0 -- Pres : [129.57555]\n",
      "Actual : 132.0 -- Pres : [128.04018]\n",
      "Actual : 135.0 -- Pres : [133.61592]\n",
      "Actual : 138.0 -- Pres : [137.09872]\n",
      "Actual : 140.0 -- Pres : [140.1358]\n",
      "Actual : 140.9 -- Pres : [140.94543]\n",
      "Actual : 146.0 -- Pres : [146.16318]\n",
      "Actual : 152.0 -- Pres : [152.52528]\n",
      "Actual : 152.8 -- Pres : [152.57472]\n",
      "Actual : 154.0 -- Pres : [157.2283]\n",
      "Actual : 157.0 -- Pres : [157.92209]\n",
      "Actual : 161.0 -- Pres : [162.85178]\n",
      "Actual : 165.0 -- Pres : [160.50334]\n",
      "Actual : 165.4 -- Pres : [168.42484]\n",
      "Actual : 165.4 -- Pres : [166.30212]\n",
      "Actual : 165.4 -- Pres : [168.88757]\n",
      "Actual : 165.4 -- Pres : [165.02853]\n",
      "Actual : 165.4 -- Pres : [168.13245]\n",
      "Actual : 171.0 -- Pres : [174.44907]\n",
      "Actual : 171.2 -- Pres : [174.34369]\n",
      "Actual : 175.0 -- Pres : [174.9419]\n",
      "Actual : 177.0 -- Pres : [178.38872]\n",
      "Actual : 182.0 -- Pres : [183.95552]\n",
      "Actual : 184.0 -- Pres : [185.52641]\n",
      "Actual : 188.0 -- Pres : [187.84857]\n",
      "Actual : 191.0 -- Pres : [195.42416]\n",
      "Actual : 191.5 -- Pres : [190.1365]\n",
      "Actual : 191.5 -- Pres : [190.27977]\n",
      "Actual : 191.5 -- Pres : [195.42624]\n",
      "Actual : 191.5 -- Pres : [194.3224]\n",
      "Actual : 191.5 -- Pres : [190.18896]\n",
      "Actual : 188.0 -- Pres : [192.92966]\n",
      "Actual : 188.6 -- Pres : [193.86395]\n",
      "Actual : 188.6 -- Pres : [192.261]\n",
      "Actual : 188.6 -- Pres : [191.70146]\n",
      "Actual : 188.6 -- Pres : [193.28238]\n",
      "Actual : 188.6 -- Pres : [192.07074]\n",
      "Actual : 188.6 -- Pres : [196.98315]\n",
      "Actual : 188.6 -- Pres : [192.06674]\n",
      "Actual : 192.0 -- Pres : [191.70338]\n",
      "Actual : 195.0 -- Pres : [202.26526]\n",
      "Actual : 195.2 -- Pres : [197.97758]\n",
      "Actual : 195.2 -- Pres : [201.8727]\n",
      "Actual : 195.2 -- Pres : [200.87971]\n",
      "Actual : 195.2 -- Pres : [197.21426]\n",
      "Actual : 200.0 -- Pres : [203.49492]\n",
      "Actual : 201.0 -- Pres : [205.4573]\n",
      "Actual : 201.7 -- Pres : [209.17055]\n",
      "Actual : 198.0 -- Pres : [202.6558]\n",
      "Actual : 196.0 -- Pres : [200.4718]\n",
      "Actual : 191.0 -- Pres : [198.25871]\n",
      "Actual : 194.0 -- Pres : [197.53607]\n",
      "Actual : 194.0 -- Pres : [197.69366]\n",
      "Actual : 194.0 -- Pres : [196.50734]\n",
      "Actual : 194.0 -- Pres : [195.87479]\n",
      "Actual : 194.0 -- Pres : [198.58282]\n",
      "Actual : 194.0 -- Pres : [199.20529]\n",
      "Actual : 194.0 -- Pres : [198.51932]\n",
      "Actual : 194.0 -- Pres : [194.66444]\n",
      "Actual : 194.0 -- Pres : [195.21971]\n",
      "Actual : 188.0 -- Pres : [191.19704]\n",
      "Actual : 188.0 -- Pres : [188.23439]\n",
      "Actual : 188.0 -- Pres : [189.18404]\n",
      "Actual : 188.0 -- Pres : [187.68369]\n",
      "Actual : 186.0 -- Pres : [186.62308]\n",
      "Actual : 186.7 -- Pres : [185.72311]\n",
      "Actual : 186.7 -- Pres : [185.17609]\n",
      "Actual : 179.0 -- Pres : [179.30952]\n",
      "Actual : 176.0 -- Pres : [181.02905]\n",
      "Actual : 176.5 -- Pres : [180.15254]\n",
      "Actual : 170.0 -- Pres : [174.9882]\n",
      "Actual : 170.7 -- Pres : [171.41118]\n",
      "Actual : 166.0 -- Pres : [170.64304]\n",
      "Actual : 166.4 -- Pres : [166.87195]\n",
      "Actual : 160.0 -- Pres : [163.54495]\n",
      "Actual : 160.6 -- Pres : [162.06134]\n",
      "Actual : 150.0 -- Pres : [152.60977]\n",
      "Actual : 150.2 -- Pres : [152.43332]\n",
      "Actual : 146.0 -- Pres : [147.33823]\n",
      "Actual : 146.9 -- Pres : [145.13806]\n",
      "Actual : 139.0 -- Pres : [141.07489]\n",
      "Actual : 139.7 -- Pres : [144.581]\n",
      "Actual : 139.0 -- Pres : [142.96858]\n",
      "Actual : 139.5 -- Pres : [142.41762]\n",
      "Actual : 135.0 -- Pres : [138.5581]\n",
      "Actual : 135.5 -- Pres : [138.07932]\n",
      "Actual : 136.0 -- Pres : [137.21344]\n",
      "Actual : 136.1 -- Pres : [138.11905]\n",
      "Actual : 132.0 -- Pres : [132.98102]\n",
      "Actual : 132.1 -- Pres : [134.61665]\n",
      "Actual : 125.0 -- Pres : [125.5527]\n",
      "Actual : 125.8 -- Pres : [124.295425]\n",
      "Actual : 124.0 -- Pres : [123.1156]\n",
      "Actual : 124.2 -- Pres : [121.3582]\n",
      "Actual : 120.0 -- Pres : [121.273735]\n",
      "Actual : 120.3 -- Pres : [119.94523]\n",
      "Actual : 115.0 -- Pres : [115.61598]\n",
      "Actual : 108.0 -- Pres : [107.97841]\n",
      "Actual : 108.6 -- Pres : [107.36789]\n",
      "Actual : 106.0 -- Pres : [102.95185]\n",
      "Actual : 101.0 -- Pres : [100.67535]\n",
      "Actual : 97.0 -- Pres : [95.5396]\n",
      "Actual : 91.0 -- Pres : [89.95724]\n",
      "Actual : 88.0 -- Pres : [89.154945]\n",
      "Actual : 80.0 -- Pres : [80.25253]\n",
      "Actual : 80.6 -- Pres : [79.05905]\n",
      "Actual : 80.6 -- Pres : [78.68013]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_train)):\n",
    "    \n",
    "    print('Actual : '+ str(y_train[i])+' -- Pres : '+str(y_pred[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model to a HDF5 file.\n",
    "# The '.h5' extension indicates that the model should be saved to HDF5.\n",
    "model.save('racerModel2.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = np.array([X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.1444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('saved_model/my_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117.16452"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = new_model.predict(XX)\n",
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:97: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Recreate the exact same model, including its weights and the optimizer\n",
    "model2 = tf.keras.models.load_model('racerModel2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.1444"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.predict(XX)\n",
    "y_pred[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
